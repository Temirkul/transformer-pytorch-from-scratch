{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 -59\n",
      "7\n",
      "7 13\n",
      "[ 3  2 69] [ 3  2 69]\n",
      "[ 0  1  4  9 16 25 36 49 64 81]\n",
      "(1, 2, 'bullet') {'x': 3, 'y': 69, 'z': 'asdf', 'kewa': 'kasdf'}\n",
      "(1, 2, 'bullet') x y z kewa\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'x' is an invalid keyword argument for print()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[106], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[39mprint\u001b[39m(args, \u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mprint\u001b[39m(args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 27\u001b[0m kwargf(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbullet\u001b[39m\u001b[39m'\u001b[39m, x\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, y\u001b[39m=\u001b[39m\u001b[39m69\u001b[39m, z\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39masdf\u001b[39m\u001b[39m'\u001b[39m, kewa \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mkasdf\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[106], line 26\u001b[0m, in \u001b[0;36mkwargf\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mprint\u001b[39m(args, kwargs)\n\u001b[0;32m     25\u001b[0m \u001b[39mprint\u001b[39m(args, \u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 26\u001b[0m \u001b[39mprint\u001b[39m(args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'x' is an invalid keyword argument for print()"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "\n",
    "\n",
    "def somefunc(array):\n",
    "    array[2] = 69\n",
    "    array[0] = 3\n",
    "    return array\n",
    "\n",
    "\n",
    "def intfunc(intg: int) -> int:\n",
    "    intg = intg - 69\n",
    "    return intg\n",
    "\n",
    "\n",
    "g = 10\n",
    "k = intfunc(g)\n",
    "print(g, k)\n",
    "g = g - 3\n",
    "print(g)\n",
    "b = g\n",
    "g += 6\n",
    "print(b, g)\n",
    "\n",
    "b = somefunc(a)\n",
    "print(a, b)\n",
    "j = np.array([i**2 for i in range(10)])\n",
    "print(j)\n",
    "\n",
    "\n",
    "def kwargf(*args, **kwargs) -> None:\n",
    "    print(args, kwargs)\n",
    "    print(args, *kwargs)\n",
    "    # print(args, **kwargs)  # this ain't valid\n",
    "\n",
    "\n",
    "kwargf(1, 2, \"bullet\", x=3, y=69, z=\"asdf\", kewa=\"kasdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field Name: x\n",
      "Field Type: <class 'int'>\n",
      "Default Value: <dataclasses._MISSING_TYPE object at 0x000001FBE0CA6310>\n",
      "---\n",
      "Field Name: y\n",
      "Field Type: <class 'int'>\n",
      "Default Value: <dataclasses._MISSING_TYPE object at 0x000001FBE0CA6310>\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, fields\n",
    "\n",
    "\n",
    "@dataclass(init=False)\n",
    "class Point:\n",
    "    x: int\n",
    "    y: int\n",
    "\n",
    "    def __init__(self, var1, var2):\n",
    "        self.var1: int = var1\n",
    "        self.var2 = var2\n",
    "\n",
    "\n",
    "point_fields = fields(Point)\n",
    "for field in point_fields:\n",
    "    print(f\"Field Name: {field.name}\")\n",
    "    print(f\"Field Type: {field.type}\")\n",
    "    print(f\"Default Value: {field.default}\")\n",
    "    # print(f\"Is Field Optional: {field.default_factory is fields.MISSING}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what? \n",
      "f <function func11 at 0x000001AB484722A0>\n",
      "func11 1 2\n",
      "p None\n",
      "-----------------\n",
      "<function appcommand.<locals>.decorator at 0x000001AB48473B00>\n",
      "what? \n",
      "f <function func12 at 0x000001AB48472CA0>\n",
      "func12 3\n",
      "u <function func12 at 0x000001AB48472CA0>\n",
      "-----------------\n",
      "func12 1\n",
      "what? \n",
      "f None\n",
      "q None\n"
     ]
    }
   ],
   "source": [
    "def appcommand():  # another way of making decorators. So basically, appcomand doesn't accept the function itself, you have to call it so that it returns the decorator function object which can be called\n",
    "    def decorator(\n",
    "        f,\n",
    "    ):  # to accept the function being decorated. When using it, need to call it by writing appcommand() (not appcomand WITHOUT the brakcets)\n",
    "        print(\"what? \")\n",
    "        print(\"f\", f)\n",
    "        # f()\n",
    "        return f\n",
    "\n",
    "    return decorator\n",
    "\n",
    "\n",
    "@appcommand()  # what ????\n",
    "def func11(\n",
    "    *args,\n",
    ") -> (\n",
    "    None\n",
    "):  # this function first goes through the decorator. After that, it is returned, which is when it gets called\n",
    "    print(\"func11\", *args)\n",
    "\n",
    "\n",
    "p = func11(1, 2)\n",
    "# p(1, 2)\n",
    "print(\"p\", p)\n",
    "print(\"-----------------\")\n",
    "x = appcommand()  # calling a function which RETURNS another decorator function. Thus, calling x() will call the inner decorator function\n",
    "print(x)\n",
    "\n",
    "def func12(*args) -> None:\n",
    "    print(\"func12\", *args)\n",
    "\n",
    "\n",
    "u = x(func12)  # returns a function into u\n",
    "u(3)\n",
    "print(\"u\", u)\n",
    "print(\"-----------------\")\n",
    "q = x(func12(1))  # func12() gets called first and then passed into the decorator\n",
    "print(\"q\", q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "!=========================================!\n",
      "x  <function decfunc.<locals>.wrappername at 0x000001FBE3E858A0>\n",
      "start\n",
      "pre f args  (1, 2, 3)\n",
      "pre f *args  1 2 3\n",
      "f input is (args, *args)\n",
      "in f args  ((1, 2, 3), 1, 2, 3)\n",
      "in f *args  (1, 2, 3) 1 2 3\n",
      "(1, 2, 3)\n",
      "1\n",
      "2\n",
      "3\n",
      "end\n",
      "rv  1\n",
      "1\n",
      "!!========================================!!\n",
      "start\n",
      "pre f args  (-5, 2)\n",
      "pre f *args  -5 2\n",
      "f input is (args, *args)\n",
      "in f args  ((-5, 2), -5, 2)\n",
      "in f *args  (-5, 2) -5 2\n",
      "(-5, 2)\n",
      "-5\n",
      "2\n",
      "end\n",
      "rv  64\n",
      "64\n",
      "func69\n",
      "!!!=======================================!!!\n",
      "in f args  (1, 2, 3, 69)\n",
      "in f *args  1 2 3 69\n",
      "1\n",
      "2\n",
      "3\n",
      "69\n",
      "1 a 3 (1, 'a', 3)\n",
      "1 <function decfunc at 0x000001FBE4B58360>\n",
      "2 <class '__main__.SomeClass'>\n",
      "3 <__main__.SomeClass object at 0x000001FBED315050>\n",
      "4 <function SomeClass.met at 0x000001FBED2CE5C0>\n",
      "5 <bound method SomeClass.met of <__main__.SomeClass object at 0x000001FBED314F90>>\n",
      "asfd\n",
      "6 None\n"
     ]
    }
   ],
   "source": [
    "from typing import Callable, Any\n",
    "\n",
    "\n",
    "def countdown(\n",
    "    n,\n",
    "):  # generator, returns a generator object which is an iterator that you can iterate over (e.g. using next())\n",
    "    while (\n",
    "        n > 0\n",
    "    ):  # iterating over the generator, the function is paused at each yield, and the yielded value is returned\n",
    "        yield n  # when you continue iterating, the function resumes execution from where it paused and continues\n",
    "        n -= 1  # until the next yield statement, and so on...\n",
    "\n",
    "\n",
    "# generators are made with the yield keyword\n",
    "counter = countdown(5)\n",
    "\n",
    "# an iterator is an object in python which has __next__ and __iter__ methods implemented, and it is used to iterate over iterables\n",
    "# one at a time, w/o having to store all the elements in memory. Values are retreived and processed on the fly (as needed)\n",
    "\n",
    "# Using next() to manually iterate through the generator\n",
    "print(next(counter))  # Output: 5\n",
    "print(next(counter))  # Output: 4\n",
    "print(next(counter))  # Output: 3\n",
    "print(next(counter))  # Output: 2\n",
    "print(next(counter))  # Output: 1\n",
    "\n",
    "print(\"!=========================================!\")\n",
    "\n",
    "\n",
    "def func(*args):\n",
    "    print(\"in f args \", args)\n",
    "    print(\"in f *args \", *args)\n",
    "    for elem in args:\n",
    "        print(elem)\n",
    "    var = 69 + args[1] if args[1] < 0 else args[1]  # conditional expression\n",
    "    return var\n",
    "\n",
    "\n",
    "def decfunc(\n",
    "    f: Callable,\n",
    ") -> (\n",
    "    Callable\n",
    "):  # accepts a function and return a function (functions are objects in python). Notice the type hinting\n",
    "    \"\"\"decorator function\"\"\"\n",
    "\n",
    "    def wrappername(\n",
    "        *args,\n",
    "    ) -> (\n",
    "        Any\n",
    "    ):  # nested wrapper function which wraps around our input function to modify the execution of the function w/o having to modify the input function itself\n",
    "        print(\"start\")\n",
    "        print(\"pre f args \", args)\n",
    "        print(\"pre f *args \", *args)\n",
    "        print(\"f input is (args, *args)\")\n",
    "        rv = f(\n",
    "            args, *args\n",
    "        )  # so basically, you should pass in *args ONLY, because when you call the function you use brackets (), meaning you implicitly pass in a tuple, hence you should\n",
    "        print(\n",
    "            \"end\"\n",
    "        )  # pass in *args because that will unpack the tuple into a tuple, thus leaving you with a tuple. If you pass in args, you will ultimately pass in a tuple within a tuple\n",
    "        print(\n",
    "            \"rv \", rv\n",
    "        )  # I pass in the result of calling f into a variable named 'rv', which is then the return value of the wrappername function\n",
    "        return rv\n",
    "\n",
    "    return wrappername  # return a function, don't call it, i.e. don't return wrappername() because you want to return the wrappername function itself (functions are objects)\n",
    "\n",
    "\n",
    "x = decfunc(\n",
    "    func\n",
    ")  # pass in the function WITHOUT any arguments because you don't wanna execute it, you just want to pass in the function itself\n",
    "print(\n",
    "    \"x \", x\n",
    ")  # The modified function is stored inside x, which you call via x(). x stores the wrappername function defined within decfunc\n",
    "y = x(1, 2, 3)  # now you call/execute the function but it's now modified.\n",
    "print(y)\n",
    "\n",
    "print(\"!!========================================!!\")\n",
    "\n",
    "\n",
    "@decfunc\n",
    "\n",
    "# a=3  # whatever is below the decorator, no matter how many spaces, will be decorated. So, a=3 will cause an error, cuz it's not a function being decorated\n",
    "\n",
    "\n",
    "def func1(*args):\n",
    "    print(\"in f args \", args)\n",
    "    print(\"in f *args \", *args)\n",
    "    for elem in args:\n",
    "        print(elem)\n",
    "    var = 69 + args[1] if args[1] < 0 else args[1]\n",
    "    return var\n",
    "\n",
    "\n",
    "def func69(\n",
    "    *args,\n",
    ") -> (\n",
    "    None\n",
    "):  # the decorator doesn't affect this, meaning it only affects the function below it\n",
    "    print(\"func69\")\n",
    "\n",
    "\n",
    "print(func1(-5, 2))\n",
    "func69()\n",
    "\n",
    "print(\"!!!=======================================!!!\")\n",
    "\n",
    "func(1, 2, 3, 69)\n",
    "\n",
    "sometup = (1, \"a\", 3)\n",
    "print(*sometup, sometup)\n",
    "\n",
    "\n",
    "# var1, var2, var3 = *sometup  # this is illegal syntax, it's applicable only inside of functions, where the star unpacks it into a single tuple\n",
    "class SomeClass:\n",
    "    def __init__(self, var):\n",
    "        self.var = var\n",
    "\n",
    "    def met(\n",
    "        self,\n",
    "    ) -> (\n",
    "        None\n",
    "    ):  # passing in the self here is crucial, without it callin SomeClass().met() will return an error\n",
    "        print(\"asfd\")\n",
    "\n",
    "\n",
    "print(\"1\", decfunc)\n",
    "print(\"2\", SomeClass)\n",
    "print(\"3\", SomeClass(_))\n",
    "print(\"4\", SomeClass.met)\n",
    "print(\"5\", SomeClass(_).met)\n",
    "print(\"6\", SomeClass(_).met())\n",
    "classinst = SomeClass(_)\n",
    "# classinst()  # this is invalid syntax because it is not callable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "somelist = [\n",
    "    i**2 for i in range(10)\n",
    "]  # list comprehension; expression for member in iterable\n",
    "print(somelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "('a', (4, 'b'), 'c')\n",
      "a 4 b c\n",
      "a (4, 'b') c\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    print(_ - 1)\n",
    "\n",
    "sometup = (\"a\", (4, \"b\"), \"c\")\n",
    "tup1, (tup2, tup3), tup4 = sometup\n",
    "tup1, tupa, tup4 = sometup\n",
    "print(sometup)\n",
    "print(tup1, tup2, tup3, tup4)\n",
    "print(tup1, tupa, tup4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert, type hinting, for _ in range(number), ..., understand and research. PEP 8 formatter\n",
    "# In the original paper each head should have seperate weights, but in your code all heads share the same weights. here are two steps to fix it:\n",
    "# 1. in __init__:  self.queries = nn.Linear(self.embed_size, self.embed_size, bias=False) (same for key and value weights)\n",
    "# 2. in forward: put \"queries = self.queries(queries)\" above \"queries = queries.reshape(...)\" (also same for keys and values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2],\n",
      "         [ 4,  3],\n",
      "         [ 5,  6]],\n",
      "\n",
      "        [[ 9, 10],\n",
      "         [ 0, -1],\n",
      "         [69, 34]]]) torch.Size([2, 3, 2])\n",
      "tensor([[[ 1,  2],\n",
      "         [ 4,  3]],\n",
      "\n",
      "        [[ 5,  6],\n",
      "         [ 9, 10]],\n",
      "\n",
      "        [[ 0, -1],\n",
      "         [69, 34]]]) torch.Size([3, 2, 2])\n",
      "tensor([[[ 1,  2,  4]],\n",
      "\n",
      "        [[ 3,  5,  6]],\n",
      "\n",
      "        [[ 9, 10,  0]],\n",
      "\n",
      "        [[-1, 69, 34]]]) torch.Size([4, 1, 3])\n",
      "tensor([ 1,  2,  4,  3,  5,  6,  9, 10,  0, -1, 69, 34]) torch.Size([12])\n",
      "tensor([ 1,  2,  4,  3,  5,  6,  9, 10,  0, -1, 69, 34]) torch.Size([12])\n",
      "tensor([[ 1,  2],\n",
      "        [ 4,  3],\n",
      "        [ 5,  6],\n",
      "        [ 9, 10],\n",
      "        [ 0, -1],\n",
      "        [69, 34]]) torch.Size([6, 2])\n",
      "tensor([ 1,  2,  4,  3,  5,  6,  9, 10,  0, -1, 69, 34]) torch.Size([12])\n",
      "tensor([[[ 1,  4,  5],\n",
      "         [ 2,  3,  6]],\n",
      "\n",
      "        [[ 9,  0, 69],\n",
      "         [10, -1, 34]]]) torch.Size([2, 2, 3])\n",
      "tensor([ 3,  5,  6,  9, 10,  0, -1, 69, 34]) tensor([1, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "# reshape play around. Internship (TUI + transformers + study QM + syllabi and dates + research do)\n",
    "tensorplay = torch.tensor([[[1, 2], [4, 3], [5, 6]], [[9, 10], [0, -1], [69, 34]]])\n",
    "print(tensorplay, tensorplay.shape)\n",
    "tensorplay1 = tensorplay.reshape(3, 2, -1)\n",
    "print(tensorplay1, tensorplay1.shape)\n",
    "tensorplay1 = tensorplay.reshape([4, 1, -1])\n",
    "print(tensorplay1, tensorplay1.shape)\n",
    "tensorplay2 = torch.flatten(tensorplay)\n",
    "print(tensorplay2, tensorplay2.shape)\n",
    "tensorplay2 = tensorplay.reshape(-1)\n",
    "print(tensorplay2, tensorplay2.shape)\n",
    "tensorplay3 = tensorplay.reshape(6, 2)\n",
    "print(tensorplay3, tensorplay3.shape)\n",
    "tensorplay5 = tensorplay3.reshape(12)\n",
    "print(tensorplay5, tensorplay5.shape)\n",
    "tensorplay4 = torch.transpose(tensorplay, 1, 2)\n",
    "print(tensorplay4, tensorplay4.shape)\n",
    "print(tensorplay5[3:], tensorplay5[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 6, 20])\n",
      "torch.Size([4, 6, 100])\n",
      "torch.Size([2, 4, 12, 40])\n",
      "torch.Size([2, 12, 4, 40])\n",
      "tensor([[1.0000, 1.4142, 1.7321, 2.0000, 8.3066],\n",
      "        [0.0000, 2.2361, 2.0000, 4.0000, 6.0000]])\n"
     ]
    }
   ],
   "source": [
    "layer = nn.Linear(20, 100)\n",
    "input = torch.randn(4, 6, 20)\n",
    "output = layer(input)\n",
    "print(input.shape)\n",
    "print(output.shape)\n",
    "# linear is pretty cool\n",
    "sometens = torch.randn(2, 4, 12, 40)\n",
    "permtens = torch.permute(sometens, (0, 2, 1, 3))\n",
    "print(sometens.shape)\n",
    "print(permtens.shape)\n",
    "print(torch.tensor([[1, 2, 3, 4, 69], [0, 5, 4, 16, 36]]) ** (1 / 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.5912, -0.9753, -4.6705,  1.2506],\n",
      "        [-0.9753,  6.2566, -3.0563, -2.1195],\n",
      "        [-4.6705, -3.0563,  9.5055, -2.8523],\n",
      "        [ 1.2506, -2.1195, -2.8523,  4.1146]])\n",
      "tensor([[ 5.5912, -0.9753, -4.6705,  1.2506],\n",
      "        [-0.9753,  6.2566, -3.0563, -2.1195],\n",
      "        [-4.6705, -3.0563,  9.5055, -2.8523],\n",
      "        [ 1.2506, -2.1195, -2.8523,  4.1146]])\n",
      "tensor([[ 5.9048, -2.4460,  0.6294, -0.5834,  0.6248],\n",
      "        [-2.4460,  5.3137, -0.3901, -0.2312,  1.6926],\n",
      "        [ 0.6294, -0.3901,  0.2663,  0.8730, -0.6148],\n",
      "        [-0.5834, -0.2312,  0.8730,  8.9054, -6.3002],\n",
      "        [ 0.6248,  1.6926, -0.6148, -6.3002,  5.0777]])\n",
      "tensor([[ 5.9048, -2.4460,  0.6294, -0.5834,  0.6248],\n",
      "        [-2.4460,  5.3137, -0.3901, -0.2312,  1.6926],\n",
      "        [ 0.6294, -0.3901,  0.2663,  0.8730, -0.6148],\n",
      "        [-0.5834, -0.2312,  0.8730,  8.9054, -6.3002],\n",
      "        [ 0.6248,  1.6926, -0.6148, -6.3002,  5.0777]])\n",
      "ein tensor([[[ 0.6642,  1.3091,  0.4851,  1.6559, -0.6190,  0.7024],\n",
      "         [ 0.3291, -1.4603, -2.8466,  5.6679,  2.9425,  1.7692],\n",
      "         [ 2.6576, -2.0879,  0.1247, -1.5756,  0.8518,  0.5165],\n",
      "         [-1.0075, -2.2839, -2.4987, -0.7886,  2.6233, -0.0256],\n",
      "         [ 0.0607,  2.2378,  2.9646, -0.4777, -1.8921, -0.1386],\n",
      "         [-1.0675,  1.8876, -1.3039,  4.2328,  0.8085,  1.3282]],\n",
      "\n",
      "        [[-0.4093, -0.3845, -0.3512,  0.3624, -0.1539,  0.2084],\n",
      "         [-1.4201,  0.0463, -1.8329,  0.1897, -0.4348,  0.2415],\n",
      "         [-0.0225,  2.8110,  1.0717, -1.7220, -0.4728, -2.6873],\n",
      "         [ 0.4198,  2.0791,  1.2238, -1.1921, -0.6188, -1.0095],\n",
      "         [-0.3290,  1.7527,  1.8774,  0.1182, -2.3939,  2.1055],\n",
      "         [ 1.0864,  4.4322,  2.0698, -3.2418,  0.2178, -4.5202]]]) torch.Size([2, 6, 6])\n",
      "bmm tensor([[[ 0.6642,  1.3091,  0.4851,  1.6559, -0.6190,  0.7024],\n",
      "         [ 0.3291, -1.4603, -2.8466,  5.6679,  2.9425,  1.7692],\n",
      "         [ 2.6576, -2.0879,  0.1247, -1.5756,  0.8518,  0.5165],\n",
      "         [-1.0075, -2.2839, -2.4987, -0.7886,  2.6233, -0.0256],\n",
      "         [ 0.0607,  2.2378,  2.9646, -0.4777, -1.8921, -0.1386],\n",
      "         [-1.0675,  1.8876, -1.3039,  4.2328,  0.8085,  1.3282]],\n",
      "\n",
      "        [[-0.4093, -0.3845, -0.3512,  0.3624, -0.1539,  0.2084],\n",
      "         [-1.4201,  0.0463, -1.8329,  0.1897, -0.4348,  0.2415],\n",
      "         [-0.0225,  2.8110,  1.0717, -1.7220, -0.4728, -2.6873],\n",
      "         [ 0.4198,  2.0791,  1.2238, -1.1921, -0.6188, -1.0095],\n",
      "         [-0.3290,  1.7527,  1.8774,  0.1182, -2.3939,  2.1055],\n",
      "         [ 1.0864,  4.4322,  2.0698, -3.2418,  0.2178, -4.5202]]]) torch.Size([2, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "xein = torch.randn(4, 5)\n",
    "yein = torch.einsum(\"ij, kj -> ik\", xein, xein)  # xx^T\n",
    "yein2 = torch.mm(xein, torch.transpose(xein, 0, 1))\n",
    "print(yein)\n",
    "print(yein2)\n",
    "yein = torch.einsum(\"ij, ik -> jk\", xein, xein)  # x^Tx\n",
    "yein2 = torch.mm(torch.transpose(xein, 0, 1), xein)\n",
    "print(yein)\n",
    "print(yein2)\n",
    "# so, essentially label the dimensions with indices and only repeat those that want to sum over and that are of equal length in that dimension. Others should be different,\n",
    "# even if their length is the same (like in the above examples), cuz you're not summing over them. Also, if want to sum, that index should not be in the output\n",
    "bein1 = torch.randn(2, 6, 5)\n",
    "bein2 = torch.randn(2, 5, 6)\n",
    "oein1 = torch.einsum(\"bij, bjk -> bik\", bein1, bein2)\n",
    "oein2 = torch.bmm(bein1, bein2)\n",
    "print(\"ein\", oein1, oein1.shape)\n",
    "print(\"bmm\", oein2, oein2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinput = torch.randn(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2066, 0.0779, 0.4895, 0.0879],\n",
      "        [0.4484, 0.0473, 0.1096, 0.0220],\n",
      "        [0.3450, 0.8748, 0.4010, 0.8900]])\n",
      "tensor([[0.2858, 0.1480, 0.2354, 0.3308],\n",
      "        [0.7335, 0.1062, 0.0623, 0.0980],\n",
      "        [0.0840, 0.2926, 0.0340, 0.5894]])\n",
      "tensor(1.) tensor(1.) tensor(1.) tensor(1.)\n",
      "tensor(1.) tensor(1.) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(torch.softmax(sinput, dim=0))\n",
    "print(torch.softmax(sinput, dim=1))\n",
    "print(\n",
    "    torch.sum(torch.softmax(sinput, dim=0)[:, 0]),\n",
    "    torch.sum(torch.softmax(sinput, dim=0)[:, 1]),\n",
    "    torch.sum(torch.softmax(sinput, dim=0)[:, 2]),\n",
    "    torch.sum(torch.softmax(sinput, dim=0)[:, 3]),\n",
    ")\n",
    "print(\n",
    "    torch.sum(torch.softmax(sinput, dim=1)[0, :]),\n",
    "    torch.sum(torch.softmax(sinput, dim=1)[1, :]),\n",
    "    torch.sum(torch.softmax(sinput, dim=1)[2, :]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AA 1\n",
      "1 2\n",
      "tensor([0., 1., 2., 3., 4., 5., 6., 7.])\n",
      "tensor([0., 1., 2., 3., 4., 5., 6., 7.])\n",
      "tensor([69., 70., 71., 72., 73., 74., 75., 76.])\n",
      "tensor([ 0.,  2.,  0.,  0.,  0., 10., 12.,  0.])\n"
     ]
    }
   ],
   "source": [
    "# test if torch tensors are modified inside functions \n",
    "class TestClass: \n",
    "    def __init__(self, a, b): \n",
    "        print('AA', a) \n",
    "        self.a = a \n",
    "        self.b = b \n",
    "    def display(self):\n",
    "        print(self.a, self.b)\n",
    "        \n",
    "TestClass(1, 2).display()\n",
    "\n",
    "def torchfunc(tensor: torch.Tensor) -> torch.Tensor: \n",
    "    dropout = nn.Dropout(p=0.5)\n",
    "    dropped = dropout(tensor)\n",
    "    tensor = tensor + 69\n",
    "    return dropped , tensor\n",
    "\n",
    "testtens = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7], dtype=torch.float32)\n",
    "print(testtens)\n",
    "droppedtens, testtens2 = torchfunc(testtens)\n",
    "print(testtens)\n",
    "print(testtens2)\n",
    "print(droppedtens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_dim: int, n_heads: int):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = embed_dim // n_heads\n",
    "\n",
    "        assert (\n",
    "            self.head_dim * n_heads == embed_dim\n",
    "        ), \"embed_dim needs to be divisible by n_heads\"\n",
    "\n",
    "        self.queries = nn.Linear(self.embed_dim, self.embed_dim, bias=False)\n",
    "        self.keys = nn.Linear(self.embed_dim, self.embed_dim, bias=False)\n",
    "        self.values = nn.Linear(self.embed_dim, self.embed_dim, bias=False)\n",
    "        self.fc_out = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        pre_queries: torch.Tensor,\n",
    "        pre_keys: torch.Tensor,\n",
    "        pre_values: torch.Tensor,\n",
    "        mask: torch.Tensor,\n",
    "    ) -> torch.Tensor:  # shape of pre_query, pre_key, pre_value are [N, seq_len, embed_dim]. It has the 'pre' prefix because they're the inputs (word vectors) to get the queries, keys, and values\n",
    "        N = pre_queries.shape[0]  # batch size\n",
    "        queries_seq_len, keys_seq_len, values_seq_len = pre_queries.shape[1], pre_keys.shape[1], pre_values.shape[1]  # sequence (sentence) lengths which may be different in encoder/decoder\n",
    "        # splitting into n_heads pieces for multihead attention\n",
    "\n",
    "        queries = self.queries(pre_queries)\n",
    "        keys = self.keys(pre_keys)\n",
    "        values = self.values(pre_values)\n",
    "\n",
    "        queries = queries.reshape(N, queries_seq_len, self.n_heads, self.head_dim)\n",
    "        keys = keys.reshape(N, keys_seq_len, self.n_heads, self.head_dim)\n",
    "        values = values.reshape(N, values_seq_len, self.n_heads, self.head_dim)\n",
    "\n",
    "        attention_grid = torch.einsum(\"nqhd, nkhd -> nhqk\", queries, keys)  # shape is [N, self.n_heads, queries_seq_len, keys_seq_len], we sum over self.head_dim\n",
    "        # you basically get the attention grid for every word in the sequence but with different attentions for every part/head of the subdivided word embeddings (self.head_dim = embed_dim // n_heads)\n",
    "\n",
    "        if mask is not None:\n",
    "            attention_grid = attention_grid.masked_fill(mask == 0, float(\"-1e20\"))\n",
    "\n",
    "        attention_weights = torch.softmax(attention_grid / self.head_dim ** (1 / 2), dim=3)  # dim=3 because they need to sum up to one along the key dimension (cuz query asks keys intuitively)\n",
    "\n",
    "        multi_head = torch.einsum(\"nhql, nlhd -> nqhd\", attention_weights, values)  # this computes all the heads which now need to be concatenated. Shape is [N, query_seq_len, self.n_heads, self.head_dim]\n",
    "        # you sum over the keys and values dimensions because that's how the math works out\n",
    "        # sum_i array[w_{1,i}*v_{i,1} ... w_{1,i}*v_{i,self.embed_dim}], hence sum over the key dimension (which is equal in length to keys_seq_len) and the values_seq_len dimension\n",
    "        # i.e., you do a linear combination of the values (word vectors) weighted by the attention_weights to FINALLY get your attention vector for the corresponding query vector\n",
    "        multi_head_attention = multi_head.reshape(N, queries_seq_len, self.embed_dim)  # concatenation, notice that it's the attention vectors for each corresponding query\n",
    "        multi_head_attention = self.fc_out(multi_head_attention)  # final weight matrix multiplication\n",
    "\n",
    "        return multi_head_attention  # shape is [N, queries_seq_len, embed_dim], i.e. the attention vector for each corresponding query vector\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, embed_dim: int, n_heads: int, dropout: float, forward_expansion: int\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.attention = SelfAttention(embed_dim, n_heads)\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        self.linear_1 = nn.Linear(embed_dim, forward_expansion * embed_dim)\n",
    "        self.linear_2 = nn.Linear(forward_expansion * embed_dim, embed_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        pre_queries: torch.Tensor,\n",
    "        pre_keys: torch.Tensor,\n",
    "        pre_values: torch.Tensor,\n",
    "        mask: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        attention = self.attention(pre_queries, pre_keys, pre_values, mask)\n",
    "        x = self.dropout(self.norm(attention + pre_queries))  # initially, the pre_queries, pre_keys, pre_values are either the same or different if in the decoder, they're just the word vectors\n",
    "        x_fc = self.linear_2(F.gelu(self.linear_1(x)))\n",
    "        out = self.dropout(self.norm(x + x_fc))\n",
    "        return out\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        src_vocab_size: int,\n",
    "        embed_dim: int,\n",
    "        n_layers: int,\n",
    "        n_heads: int,\n",
    "        device: torch.device,\n",
    "        forward_expansion: int,\n",
    "        dropout: float,\n",
    "        max_seq_length: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.word_embedding = nn.Embedding(src_vocab_size, embed_dim)\n",
    "        self.positional_embedding = nn.Embedding(max_seq_length, embed_dim)\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                TransformerBlock(embed_dim, n_heads, dropout, forward_expansion)\n",
    "                for _ in range(n_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, mask: torch.Tensor) -> torch.Tensor:\n",
    "        N, seq_length = x.shape  # x is the input tensor which contains the sentences and words, i.e. its shape is N x seq_length, where N = batch size and seq_length = sentence size (note: seq_length = max_seq_length)\n",
    "        positions = torch.arange(0, seq_length).expand(N, -1).to(self.device)\n",
    "        out = self.dropout(self.word_embedding(x) + self.positional_embedding(positions))  # these are the word vectors\n",
    "        for layer in self.layers:\n",
    "            out = layer(out, out, out, mask)  # calling the forward method of the TransformerBlock\n",
    "        return out\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim: int,\n",
    "        n_heads: int,\n",
    "        forward_expansion: int,\n",
    "        dropout: float,\n",
    "        device: torch.device,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        self.attention = SelfAttention(embed_dim, n_heads)\n",
    "        self.transformer_block = TransformerBlock(embed_dim, n_heads, dropout, forward_expansion)\n",
    "        self.device = device\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        keys: torch.Tensor,\n",
    "        values: torch.Tensor,\n",
    "        src_mask: torch.Tensor,\n",
    "        trg_mask: torch.Tensor,\n",
    "    ) -> torch.Tensor:  # src_mask is optional, it's so that we don't do computations on padded values. trg_mask is not optional, you MUST have it\n",
    "        attention = self.attention(x, x, x, trg_mask)\n",
    "        queries = self.dropout(self.norm(x + attention))  # the queries in the decoder which get passed into the second multiheaded attention\n",
    "        out = self.transformer_block(queries, keys, values, src_mask)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        trg_vocab_size: int,\n",
    "        embed_dim: int,\n",
    "        n_layers: int,\n",
    "        n_heads: int,\n",
    "        device: torch.device,\n",
    "        forward_expansion: int,\n",
    "        dropout: float,\n",
    "        max_seq_length: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.word_embedding = nn.Embedding(trg_vocab_size, embed_dim)\n",
    "        self.positional_embedding = nn.Embedding(max_seq_length, embed_dim)\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                DecoderBlock(embed_dim, n_heads, forward_expansion, dropout, device)\n",
    "                for _ in range(n_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.fc_out = nn.Linear(embed_dim, trg_vocab_size)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        encoder_out: torch.Tensor,\n",
    "        src_mask: torch.Tensor,\n",
    "        trg_mask: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        N, seq_length = x.shape\n",
    "        positions = torch.arange(0, seq_length).expand(N, -1).to(self.device)\n",
    "        x = self.dropout(self.word_embedding(x) + self.positional_embedding(positions))\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, encoder_out, encoder_out, src_mask, trg_mask)  # encoder output is the attention vector which went through the feedforward nets & normalization + skip connection\n",
    "        out = torch.softmax(self.fc_out(x), dim=1)  # shape is [N, trg_vocab_size]\n",
    "        return out\n",
    "\n",
    "\n",
    "# think about how everything works and the dimensionality and the masks, make sure to understand everything and how encoding (tokenization) work with word embeddings and everything else (attention)\n",
    "# think about the vocab sizes and the masks (why should only the DECODER be masked?). Undertand the MASKS and vocabs and MAX_SEQ_LENGTH\n",
    "\n",
    "# tmrw: transformer code finish & TUI 8 pm + set research code running and do the research tasks + D3 and calcium figure out and start skincare + research formulae \n",
    "\n",
    "# UNDERSTAND THE PROBABILITY DISTROS IN NLP (LEARNING TASK, see the papers)\n",
    "# find a dataset for translation (in kaggle, huggingface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatGPT(nn.Module): \n",
    "    def __init__(self, src_voab_size:int, trg_vocab_size: int, embed_dim: int, n_layers: int, n_heads: int, device: torch.device, forward_expansion: int, dropout: float, max_seq_length: int): \n",
    "        super().__init__()\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        pass \n",
    "\n",
    "\n",
    "class Translator(nn.Module):   \n",
    "    def __init__(\n",
    "        self, \n",
    "        src_vocab_size: int, \n",
    "        trg_vocab_size: int, \n",
    "        src_pad_idx: int, \n",
    "        trg_pad_idx: int, \n",
    "        embed_dim: int, \n",
    "        n_layers: int, \n",
    "        n_heads: int, \n",
    "        device: torch.device, \n",
    "        forward_expansion: int, \n",
    "        dropout: float, \n",
    "        max_seq_length: int\n",
    "    ):\n",
    "        super().__init__() \n",
    "        \n",
    "        self.encoder = Encoder(\n",
    "            src_vocab_size, \n",
    "            embed_dim, \n",
    "            n_layers, \n",
    "            n_heads, \n",
    "            device, \n",
    "            forward_expansion, \n",
    "            dropout, \n",
    "            max_seq_length\n",
    "        )\n",
    "        \n",
    "        self.decoder = Decoder(\n",
    "            trg_vocab_size, \n",
    "            embed_dim, \n",
    "            n_layers, \n",
    "            n_heads, \n",
    "            device, \n",
    "            forward_expansion, \n",
    "            dropout, \n",
    "            max_seq_length\n",
    "        )\n",
    "        \n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        self.device = device \n",
    "        \n",
    "    def make_src_mask(self, src) -> torch.Tensor:  # src is of shape [N, src sentence length]\n",
    "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)  # understand this. Shape is [N, 1, 1, src sentece length], makes this broadcastable \n",
    "        return src_mask.to(self.device)\n",
    "    \n",
    "    def make_trg_mask(self, trg) -> torch.Tensor:\n",
    "        N, trg_length = trg.shape\n",
    "        trg_mask = torch.tril(torch.ones(trg_length, trg_length)).expand(N, 1, trg_length, trg_length) \n",
    "        return trg_mask.to(self.device)\n",
    "              \n",
    "    def forward(\n",
    "        self, \n",
    "        src: torch.Tensor,  # WHAT EXACTLY IS SRC AND TRG? The source and target sentences i suppose \n",
    "        trg: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        src_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.make_src_mask(trg)\n",
    "        encoder_src = self.encoder(src, src_mask)\n",
    "        out = self.decoder(trg, encoder_src, src_mask, trg_mask)\n",
    "        return out \n",
    "    \n",
    "    # understand how it all ties together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a tensor([[1, 2],\n",
      "        [3, 4]]) torch.Size([2, 2])\n",
      "b tensor([[[1, 2],\n",
      "         [3, 4]]]) torch.Size([1, 2, 2]) \n",
      " tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "c tensor([[[1, 2]],\n",
      "\n",
      "        [[3, 4]]]) torch.Size([2, 1, 2]) \n",
      " tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "d tensor([[[1],\n",
      "         [2]],\n",
      "\n",
      "        [[3],\n",
      "         [4]]]) torch.Size([2, 2, 1]) \n",
      " tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[False,  True],\n",
      "        [False, False]]) \n",
      " tensor([[ True, False],\n",
      "        [ True,  True]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "e = 2\n",
    "f = (a == e)\n",
    "print('a', a, a.shape) \n",
    "b = a.unsqueeze(0)\n",
    "print('b', b, b.shape, '\\n', b[0, :, :])\n",
    "c = a.unsqueeze(1)\n",
    "print('c', c, c.shape, '\\n', c[:, 0, :])\n",
    "d = a.unsqueeze(2)  # range of possible unsqueeze argument values is [-3, 2]\n",
    "print('d', d, d.shape, '\\n', d[:, :, 0])\n",
    "print(f, '\\n', f == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3459,  1.6685, -0.0150],\n",
      "        [ 1.4803,  0.5445,  0.0353]])\n",
      "tensor([[0.1011, 0.7581, 0.1408],\n",
      "        [0.6142, 0.2410, 0.1448]])\n",
      "tensor([[-1.2558,  0.0000,  0.0000,  0.0000],\n",
      "        [-1.0626, -0.8592,  0.0000,  0.0000],\n",
      "        [-0.5719,  0.2874, -0.0259,  0.0000],\n",
      "        [-0.0635, -0.4276,  1.0535, -0.2341]])\n"
     ]
    }
   ],
   "source": [
    "m = nn.Softmax(dim=1)\n",
    "input = torch.randn(2, 3)\n",
    "output = m(input)\n",
    "print(input)\n",
    "print(output)\n",
    "asd = torch.randn(4, 4)\n",
    "print(torch.tril(asd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(10, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.2097e-01, -6.5288e-01,  5.8031e-03, -1.5795e+00],\n",
       "        [-1.7667e+00, -1.4778e-03,  3.7534e-01,  4.3692e-01],\n",
       "        [-1.4814e+00, -5.5933e-01, -1.0190e-01,  6.0000e-01],\n",
       "        [-7.3397e-01,  2.3712e-01,  6.7632e-01, -3.9567e-01],\n",
       "        [-1.6704e+00, -1.3662e-01,  8.7118e-01,  7.5154e-01],\n",
       "        [ 2.6692e-01, -8.9575e-01, -2.0876e-02, -1.2119e+00],\n",
       "        [-1.3995e-02, -4.0364e-01, -7.1366e-01,  1.3797e+00],\n",
       "        [ 7.8857e-02,  8.3519e-01,  4.6091e-01, -1.3989e+00],\n",
       "        [-1.0316e+00, -1.3021e+00, -1.7873e+00, -3.0839e-01],\n",
       "        [-6.5690e-01,  1.5618e+00, -4.4255e-02,  1.3002e+00]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = nn.Embedding(10, 4)  \n",
    "print(emb)\n",
    "emb.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 3],\n",
      "        [5, 5]]) torch.Size([2, 2])\n",
      "tensor([[[-1.4814, -0.5593, -0.1019,  0.6000],\n",
      "         [-0.7340,  0.2371,  0.6763, -0.3957]],\n",
      "\n",
      "        [[ 0.2669, -0.8958, -0.0209, -1.2119],\n",
      "         [ 0.2669, -0.8958, -0.0209, -1.2119]]], grad_fn=<EmbeddingBackward0>) torch.Size([2, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "tens = torch.tensor([[2, 3], [5, 5]])  # represents tokenized sentences with a batch size of 2 \n",
    "print(tens, tens.shape)\n",
    "embedded = emb(tens) \n",
    "print(embedded, embedded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0-1): 2 x TransformerBlock(\n",
      "    (attention): SelfAttention(\n",
      "      (queries): Linear(in_features=5, out_features=5, bias=False)\n",
      "      (keys): Linear(in_features=5, out_features=5, bias=False)\n",
      "      (values): Linear(in_features=5, out_features=5, bias=False)\n",
      "      (fc_out): Linear(in_features=5, out_features=5, bias=True)\n",
      "    )\n",
      "    (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "    (linear_1): Linear(in_features=5, out_features=15, bias=True)\n",
      "    (linear_2): Linear(in_features=15, out_features=5, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ") 2\n",
      "exec\n",
      "exec\n",
      "exec\n",
      "exec\n",
      "exec\n"
     ]
    }
   ],
   "source": [
    "layers = nn.ModuleList(\n",
    "            [TransformerBlock(5, 5, 1/10, 3) for _ in range(2)]\n",
    "        )\n",
    "print(layers, len(layers))\n",
    "for _ in range(5):\n",
    "    print('exec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3, -2, -1,  0,  1,  2,  3,  4]) torch.Size([8])\n",
      "tensor([[-3, -2, -1,  0,  1,  2,  3,  4],\n",
      "        [-3, -2, -1,  0,  1,  2,  3,  4],\n",
      "        [-3, -2, -1,  0,  1,  2,  3,  4]]) torch.Size([3, 8])\n",
      "tensor([[-3, -2, -1,  0,  1,  2,  3,  4],\n",
      "        [-3, -2, -1,  0,  1,  2,  3,  4],\n",
      "        [-3, -2, -1,  0,  1,  2,  3,  4]]) torch.Size([3, 8])\n",
      "tensor([[[-3, -2, -1,  0,  1,  2,  3,  4],\n",
      "         [-3, -2, -1,  0,  1,  2,  3,  4]],\n",
      "\n",
      "        [[-3, -2, -1,  0,  1,  2,  3,  4],\n",
      "         [-3, -2, -1,  0,  1,  2,  3,  4]],\n",
      "\n",
      "        [[-3, -2, -1,  0,  1,  2,  3,  4],\n",
      "         [-3, -2, -1,  0,  1,  2,  3,  4]],\n",
      "\n",
      "        [[-3, -2, -1,  0,  1,  2,  3,  4],\n",
      "         [-3, -2, -1,  0,  1,  2,  3,  4]],\n",
      "\n",
      "        [[-3, -2, -1,  0,  1,  2,  3,  4],\n",
      "         [-3, -2, -1,  0,  1,  2,  3,  4]]]) torch.Size([5, 2, 8])\n",
      "tensor([[-0.5650,  0.8798,  0.0707],\n",
      "        [ 2.7031,  0.0204, -0.7219],\n",
      "        [-0.9288, -0.5120,  0.6686]]) torch.Size([3, 3])\n",
      "tensor([[[[-0.5650,  0.8798,  0.0707],\n",
      "          [ 2.7031,  0.0204, -0.7219],\n",
      "          [-0.9288, -0.5120,  0.6686]]],\n",
      "\n",
      "\n",
      "        [[[-0.5650,  0.8798,  0.0707],\n",
      "          [ 2.7031,  0.0204, -0.7219],\n",
      "          [-0.9288, -0.5120,  0.6686]]],\n",
      "\n",
      "\n",
      "        [[[-0.5650,  0.8798,  0.0707],\n",
      "          [ 2.7031,  0.0204, -0.7219],\n",
      "          [-0.9288, -0.5120,  0.6686]]],\n",
      "\n",
      "\n",
      "        [[[-0.5650,  0.8798,  0.0707],\n",
      "          [ 2.7031,  0.0204, -0.7219],\n",
      "          [-0.9288, -0.5120,  0.6686]]],\n",
      "\n",
      "\n",
      "        [[[-0.5650,  0.8798,  0.0707],\n",
      "          [ 2.7031,  0.0204, -0.7219],\n",
      "          [-0.9288, -0.5120,  0.6686]]]]) torch.Size([5, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "arr = torch.arange(-3, 5)\n",
    "print(arr, arr.shape)\n",
    "arr1 = arr.expand(3, 8)\n",
    "print(arr1, arr1.shape)\n",
    "arr2 = arr.expand(3, -1)\n",
    "print(arr2, arr2.shape)\n",
    "arr3 = arr.expand(5, 2, -1)\n",
    "print(arr3, arr3.shape)\n",
    "arr = torch.randn(3, 3)\n",
    "print(arr, arr.shape)\n",
    "arr4 = arr.expand(5, 1, 3, 3)\n",
    "print(arr4, arr4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False 0\n",
      "2.0 1.9000000000000004 1 2 3\n"
     ]
    }
   ],
   "source": [
    "num_set = {}\n",
    "print(3 in num_set, len(num_set))\n",
    "print(5.9 // 2, 5.9 % 2, 3 // 2, 10 // 5, 10 // 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temirkul",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
